include:
  - template: Code-Quality.gitlab-ci.yml
  - template: Jobs/SAST.gitlab-ci.yml
  - template: Jobs/Secret-Detection.gitlab-ci.yml
  - project: "dev/ext-project-packaging/ci-includes"
    file: "linotp-container-ci-upload.yml"

variables:
  LANG: C.UTF-8
  DOCKERFY_URL: https://debs-devel.corp.linotp.de/misc/dockerfy/dockerfy
  DOCKER_TAGS: $CI_PIPELINE_ID
  IMAGE_PREFIX_CI: $CI_REGISTRY/$CI_PROJECT_PATH/ci
  DOCKER_COMPOSE_VERSION: "1.22.0"
  # Docker network per build - needed for DNS resolution between services (service linotp needs db)
  FF_NETWORK_PER_BUILD: 1
  BLACKDOG_LDAP_IMAGE: $CI_REGISTRY/docker-images/blackdog-ldap/blackdog-ldap:latest
  BLACKDOG_MYSQL_IMAGE: $CI_REGISTRY/docker-images/blackdog-mysql/blackdog-mysql:latest
  BLACKDOG_SAMBA_IMAGE: $CI_REGISTRY/docker-images/blackdog-samba/blackdog-samba:latest
  PYPI_IMAGE_TAG: $IMAGE_PREFIX_CI/$CI_COMMIT_REF_SLUG-pypi:$CI_PIPELINE_ID
  DOCKER_IMAGE_TAG: $CI_REGISTRY_IMAGE/b/$CI_COMMIT_REF_SLUG:$CI_PIPELINE_ID
  DOCKER_TEST_IMG_IMAGE_TAG: $IMAGE_PREFIX_CI/$CI_COMMIT_REF_SLUG-testimg:$CI_PIPELINE_ID
  DOCKER_TEST_ENV_IMAGE_TAG: $IMAGE_PREFIX_CI/$CI_COMMIT_REF_SLUG-testenv:$CI_PIPELINE_ID
  DOCKER_RELEASE_IMAGE: $CI_REGISTRY_IMAGE/linotp
  # Variables for security scan evaluation
  SECRET_DETECTION_REPORT_FILE: gl-secret-detection-report.json
  SAST_DETECTION_REPORT_FILE: gl-sast-report.json
  # uncomment `CI_DEBUG_SERVICES` to capture logs of job-services (e.g. the linotp container in e2e tests)
  # CI_DEBUG_SERVICES: "true"
  # Name of the image in the registries:
  REGISTRY_IMAGE_NAME: "linotp/linotp"
  # The upload stage needs this as `BUILD_IMAGE_TAG`
  BUILD_IMAGE_TAG: "$DOCKER_IMAGE_TAG"

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule' # Execute nightly pipeline
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"' # Execute pipeline in merge request context
    - if: '$CI_PIPELINE_SOURCE == "web"' # Execute pipeline manually triggered from the web
    - if: $CI_COMMIT_TAG # Execute pipeline on release tag
    - if: "$CI_COMMIT_BRANCH =~ /^(branch-v|master)/" # Execute pipeline when a new commit is pushed to a stable or master branch
    - if: $NIGHTLY_PIPELINE # Execute pipeline if run with this variable set

stages:
  - check-and-build
  - test
  - lint
  - apidocs
  - upload

# Docker registry access
.docker-registry: &docker-registry
  docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY

build-pypi:
  stage: check-and-build
  needs: []
  image: docker:latest
  before_script:
    - !reference [.docker-registry]
  script:
    - docker build -t "$PYPI_IMAGE_TAG" -f docker/Dockerfile.linotp --target testenv-pypi .
    - docker push "$PYPI_IMAGE_TAG"

build-docker:
  stage: check-and-build
  needs: []
  image: docker:latest
  before_script:
    - !reference [.docker-registry]
  script:
    # We're using labels to add some interesting build metadata to the
    # container image. This makes it easier to identify exactly what is
    # in the image. The `IMAGE_VERSION` maps any version number like
    # `.devX` or `.rcY` to `.0`.
    - |
      IMAGE_VERSION="$(sed -Ene '/__version__ =/{s/^.*= "(.*)"/\1/;s/\.(dev|rc)[0-9]+/.0/;p}' linotp/__init__.py)"
      DATE=$(date +"%Y%m%d")
      LABEL_ARGS="
        --label de.linotp.commit-ref=$CI_COMMIT_REF_NAME
        --label de.linotp.commit-hash=$CI_COMMIT_SHORT_SHA
        --label de.linotp.image-tag=$IMAGE_VERSION-$DATE
        --label de.linotp.version=$IMAGE_VERSION
      "

      # Build all images with the same labels
      docker build -t "$DOCKER_IMAGE_TAG" $LABEL_ARGS -f docker/Dockerfile.linotp .
      docker push "$DOCKER_IMAGE_TAG"
      docker build -t "$DOCKER_TEST_ENV_IMAGE_TAG" $LABEL_ARGS --target testenv -f docker/Dockerfile.linotp .
      docker push "$DOCKER_TEST_ENV_IMAGE_TAG"
      docker build -t "$DOCKER_TEST_IMG_IMAGE_TAG" $LABEL_ARGS --target testimg -f docker/Dockerfile.linotp .
      docker push "$DOCKER_TEST_IMG_IMAGE_TAG"

container_scanning:
  image:
    name: docker.io/aquasec/trivy:latest
    entrypoint: [""]
  needs: ["build-docker"]
  variables:
    # SEVERITIES: CRITICAL,HIGH
    GIT_STRATEGY: none
    TRIVY_USERNAME: "$CI_REGISTRY_USER"
    TRIVY_PASSWORD: "$CI_REGISTRY_PASSWORD"
    TRIVY_AUTH_URL: "$CI_REGISTRY"
    FULL_IMAGE_NAME: $DOCKER_IMAGE_TAG
  script:
    - trivy --version
    # cache cleanup is needed when scanning images with the same tags, it does not remove the database
    - time trivy clean --all
    # update vulnerabilities db
    - time trivy image --download-db-only --no-progress --cache-dir .trivycache/
    # Builds report and puts it in the default workdir $CI_PROJECT_DIR, so `artifacts:` can take it from there
    - time trivy image --scanners vuln --exit-code 0 --cache-dir .trivycache/ --no-progress --format template --template "@/contrib/gitlab.tpl"
      --output "$CI_PROJECT_DIR/gl-container-scanning-report.json" "$FULL_IMAGE_NAME"
    # Prints full report
    - time trivy image --scanners vuln --exit-code 0 --cache-dir .trivycache/ --no-progress "$FULL_IMAGE_NAME"
    - time trivy image --scanners vuln --exit-code 1 --cache-dir .trivycache/ ${SEVERITIES:+--severity ${SEVERITIES}} --ignore-unfixed --no-progress "$FULL_IMAGE_NAME"
  cache:
    paths:
      - .trivycache/
  # Enables https://docs.gitlab.com/ee/user/application_security/container_scanning/ (Container Scanning report is available on GitLab EE Ultimate or GitLab.com Gold)
  artifacts:
    when: always
    expose_as: container_scanning
    paths:
      - $CI_PROJECT_DIR/gl-container-scanning-report.json
    expire_in: 2 weeks
    reports:
      container_scanning: gl-container-scanning-report.json

secret_detection:
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  artifacts:
    paths:
      - $SECRET_DETECTION_REPORT_FILE
    expire_in: 1 hour

.report_evaluation:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  variables:
    SEVERITIES: "Critical,High"
    GIT_STRATEGY: none
  cache: {}
  before_script:
    - apt-get install -y jq
  script:
    - |
      if [ -f "$REPORT_FILE" ]; then
        VULNERABILITIES_COUNT=$(jq --arg severities "$SEVERITIES" '.vulnerabilities | map(select(.severity as $s | $severities | split(",") | any(. == $s))) | length' "$REPORT_FILE")
        if [ "$VULNERABILITIES_COUNT" -gt 0 ]; then
          echo "Vulnerabilities detected. Please analyze the artifact $REPORT_FILE used by the '${CI_JOB_NAME}' job."
          jq --arg severities "$SEVERITIES" '.vulnerabilities | map(select(.severity as $s | $severities | split(",") | any(. == $s)))' "$REPORT_FILE"
          exit 80
        else
          echo "No vulnerabilities detected."
        fi
      else
        echo "Artifact $REPORT_FILE does not exist. The job creating it for '${CI_JOB_NAME}' likely didn't create one. Hence, no evaluation can be performed."
      fi

secret_detection_evaluation:
  extends: .report_evaluation
  needs: ["secret_detection"]
  variables:
    REPORT_FILE: $SECRET_DETECTION_REPORT_FILE

semgrep-sast:
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  variables:
    SAST_SEMGREP_METRICS: "false"
  artifacts:
    paths:
      - $SAST_DETECTION_REPORT_FILE
    expire_in: 1 hour

semgrep-sast_evaluation:
  extends: .report_evaluation
  needs: ["semgrep-sast"]
  variables:
    REPORT_FILE: $SAST_DETECTION_REPORT_FILE

pre-commit-check:
  stage: check-and-build
  needs: []
  image: ghcr.io/astral-sh/uv:python3.11-bookworm
  interruptible: true
  cache:
    paths:
      - $CI_PROJECT_DIR/.pre-commit-cache
  rules:
    - exists:
        - .pre-commit-config.yaml
  before_script:
    - uv tool install pre-commit --with pre-commit-uv --force-reinstall
  script:
    - PRE_COMMIT_HOME=$CI_PROJECT_DIR/.pre-commit-cache uvx pre-commit run --all-files

lint:
  stage: lint
  needs: []
  when: manual
  image: python:3.11-bookworm
  interruptible: true
  variables:
    EXIT_ON_FATAL: "1"
    EXIT_ON_ERROR: "0"
    EXIT_ON_WARNING: "0"
  before_script:
    - pip install pylint
  script:
    - pylint linotp/${LINTED_MODULE} && STATUS=0 || STATUS=$?
    - echo STATUS:$STATUS
    - "test $(( $STATUS & 32 )) -eq 0 || (echo 'Fail: usage error'; false)"
    - "test $(( $EXIT_ON_FATAL && $STATUS & 1 )) -eq 0 || (echo 'Fail: Fatal errors'; false)"
    - "test $(( $EXIT_ON_ERROR && $STATUS & 2 )) -eq 0 || (echo 'Fail: Errors'; false)"
    - "test $(( $EXIT_ON_WARNING && $STATUS & 4 )) -eq 0 || (echo 'Fail: Warnings'; false)"
  parallel:
    matrix:
      - LINTED_MODULE:
          [controllers, lib, model, provider, tokens, useridresolver]

# Provide pytest arguments based on base rules
# The tests need a number of arguments based on the type
# of job they represent. (database type, parallel run, nightly, etc.).
# We also need do decide whether to include parallel arguments depending on
# the job variables provided. We implement this as a shell command so that
# we can make use of the shell to put all the pieces together in once place.
#
# Pytest arguments can be specified in these variables:
#  NIGHTLY_ARGS     - Only used if this is a nightly (extended) pipeline or merge-train
#  NON_NIGHTLY_ARGS - Only used for normal pipelines (MRs, merges, tags)
#  ALL_JOB_ARGS     - Both nightly and non-nightly jobs
#
# Behaviour configuration:
#  NIGHTLY_PIPELINE - If set, the pipeline runs in nightly mode and enables an
#                     extended set of tests
#
# Other variables used:
#  CI_JOB_NAME      - the test report file is derived from the job name
#  CI_NODE_TOTAL    - parallel run configuration
#  CI_NODE_INDEX
.pytest-args: &pytest-args |
  # Junit XML filename is based on the job name
  PYTESTARGS="--junitxml=`echo ${CI_JOB_NAME} | tr ' /' '_'`.xml"
  if [ -n "${CI_NODE_INDEX}" ]; then
    PYTESTARGS="$PYTESTARGS --test-group-count=${CI_NODE_TOTAL} --test-group=${CI_NODE_INDEX}"
  fi
  # Add arguments from job definition
  PYTESTARGS="$PYTESTARGS ${ALL_JOB_ARGS}"
  # Job definition of nightly / non-nightly arguments
  if [ -n "${NIGHTLY_PIPELINE}" ]; then
    PYTESTARGS="$PYTESTARGS ${NIGHTLY_ARGS}"
  else
    PYTESTARGS="$PYTESTARGS ${NON_NIGHTLY_ARGS}"
  fi
  #
  if [ -n "${PYPI_ARGS}" ]; then
    PYTESTARGS="$PYTESTARGS ${PYPI_ARGS}"
  fi
  # Coverage report
  PYTESTARGS="$PYTESTARGS --cov=linotp --cov-report=xml:${CI_PROJECT_DIR}/coverage.xml"

# Nightly tests are scheduled to run once a day and contain
# more tests than the regular set
# Merge_trains and tag-pipelines too run against more to prevent a broken master
.nightly-test-set-rules:
  rules:
    - if: $NIGHTLY_PIPELINE
      when: always
    - if: $CI_MERGE_REQUEST_EVENT_TYPE == 'merge_train' || $CI_COMMIT_TAG
      variables:
        NIGHTLY_PIPELINE: 1
      when: always

# The next sections provide different database configurations
.mysql-vars: &mysql-vars
  MYSQL_DATABASE: linotp_db
  MYSQL_ROOT_PASSWORD: rootpass
  MYSQL_USER: linotp
  MYSQL_PASSWORD: linotppass
  LINOTP_DB_HOST: "db"
  LINOTP_DB_PORT: "3306"
  LINOTP_DB_WAITTIME: 2m
  LINOTP_DATABASE_URI: "mysql+mysqldb://linotp:linotppass@db/linotp_db?charset=utf8"
  LINOTP_PYTEST_DATABASE_URI: "mysql+mysqldb://linotp:linotppass@db/linotp_db?charset=utf8"

.mariadb-database:
  rules:
    - !reference [.nightly-test-set-rules, rules]
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  variables:
    <<: *mysql-vars
    DB: mariadb:10.1
  services:
    - name: ${DB}
      alias: db

.mysql-database:
  extends:
    - .nightly-test-set-rules
  variables:
    <<: *mysql-vars
    DB: mysql:5.5
  services:
    - name: ${DB}
      alias: db
      command:
        [
          "mysqld",
          "--character-set-server=utf8",
          "--collation-server=utf8_general_ci",
        ]

.mysql-lower-case-table-names-database:
  extends:
    - .nightly-test-set-rules
  variables:
    <<: *mysql-vars
    DB: mysql:5.5
  services:
    - name: ${DB}
      alias: db
      command:
        [
          "mysqld",
          "--character-set-server=utf8",
          "--collation-server=utf8_general_ci",
          "--lower-case-table-names=1",
        ]
  script:
    # check that config table is stored lower case, i.e. the tests executed verify that lower case table names work.
    - |
      TABLES=$(python3 -c "from sqlalchemy import create_engine, inspect; print(*inspect(create_engine('$LINOTP_DATABASE_URI')).get_table_names(), sep='\n')")
      echo $TABLES
      if [[ "$TABLES" =~ "Config" || ! "$TABLES" =~ "config" ]]; then
        echo "ERROR: Expected to find table 'config' and not 'Config' in lower case table name tests."
        exit 1
      fi

.postgres-database:
  extends:
    - .nightly-test-set-rules
  variables:
    DB: postgres:12
    POSTGRES_DB: linotp_db
    POSTGRES_USER: linotp
    POSTGRES_PASSWORD: "linotppass"
    POSTGRES_HOST_AUTH_METHOD: trust
    LINOTP_DB_HOST: "db"
    LINOTP_DB_PORT: "5432"
    LINOTP_DB_WAITTIME: 2m
    LINOTP_DATABASE_URI: postgres://linotp:linotppass@db/linotp_db # gitleaks:allow
    LINOTP_PYTEST_DATABASE_URI: postgres://linotp:linotppass@db/linotp_db # gitleaks:allow
  services:
    - name: ${DB}
      alias: db

## Test stages
.test-base:
  interruptible: true
  parallel: 4
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: ${CI_PROJECT_DIR}/coverage.xml
  before_script:
    - *pytest-args

.test-base-pypi:
  extends: .test-base
  stage: test
  needs: [build-pypi]
  image: $PYPI_IMAGE_TAG
  rules:
    - if: $CI_MERGE_REQUEST_EVENT_TYPE == 'merged_result'
  variables:
    PYPI_ARGS: "-n auto"

unit-test:
  extends: .test-base-pypi
  artifacts:
    reports:
      junit: linotp/tests/unit/unit-*.xml
  script:
    - make unittests PYTESTARGS="$PYTESTARGS"

.functional-test-base:
  extends:
    - .test-base-pypi
  artifacts:
    reports:
      junit: linotp/tests/functional/functional-*.xml
  script:
    - make functionaltests PYTESTARGS="$PYTESTARGS"

functional-test:
  extends:
    - .functional-test-base

.functional-test-db-base:
  extends:
    - .functional-test-base
  variables:
    PYPI_ARGS: ""
  script:
    - echo "Waiting for database to be accessible at ${LINOTP_DB_HOST}:${LINOTP_DB_PORT}..."
    - >
      for i in {1..30}; do
        if nc -z $LINOTP_DB_HOST $LINOTP_DB_PORT; then
          echo "Database is accessible at ${LINOTP_DB_HOST}:${LINOTP_DB_PORT}!";
          break;
        fi;
        echo "Attempt $i/30: Database at ${LINOTP_DB_HOST}:${LINOTP_DB_PORT} is not yet ready...";
        sleep 5;
      done;
      if ! nc -z $LINOTP_DB_HOST $LINOTP_DB_PORT; then
        echo "Failed to connect to database at ${LINOTP_DB_HOST}:${LINOTP_DB_PORT} after 30 attempts.";
        exit 1;
      fi
    - !reference [".functional-test-base", "script"]

functional-test-mariadb:
  extends:
    - .functional-test-db-base
    - .mariadb-database
    - .nightly-test-set-rules

functional-test-postgres:
  extends:
    - .functional-test-db-base
    - .postgres-database

functional-test-mysql:
  extends:
    - .functional-test-db-base
    - .mysql-database

functional-test-mysql-lower-case-table-names:
  extends:
    - .functional-test-db-base
    - .mysql-lower-case-table-names-database
  script:
    - !reference [".functional-test-db-base", "script"]
    - !reference [".mysql-lower-case-table-names-database", "script"]

.e2e-test:
  extends:
    - .test-base
  image: $DOCKER_TEST_ENV_IMAGE_TAG
  needs: [build-docker]
  variables:
    LINOTP_HOST: "test-linotp"
    LINOTP_PORT: "5000"
    LINOTP_PROTOCOL: "http"
    LINOTP_USERNAME: "admin"
    LINOTP_PASSWORD: "admin"
    HEALTHCHECK_PORT: "80"
    SELENIUM_DRIVER: "chrome"
    SELENIUM_PROTOCOL: "http"
    SELENIUM_HOST: "test-chrome"
    SELENIUM_PORT: "4444"
  services:
    - name: $BLACKDOG_LDAP_IMAGE
      alias: blackdog-ldap
    - name: $BLACKDOG_MYSQL_IMAGE
      alias: blackdog-mysql
    - name: $BLACKDOG_SAMBA_IMAGE
      alias: blackdog-samba
    # Note: after 4.30.0-20250323 Chrome will throw a popup "Change your password" when they found it in a data breach.
    # This popup can't currently be disabled or intercepted -> breaking some tests.
    # What's making it even worse: That popup is not shown in the Screenshots taken by the tests.
    # (But you can see it via VNC in local e2e tests)
    # We should check if this is fixed in upcoming versions from time to time.
    - name: selenium/standalone-chrome:4.30.0-20250323
      alias: test-chrome
    # implicitly start linotp latest, as it relies on the DB
    - name: $DOCKER_TEST_IMG_IMAGE_TAG
      alias: test-linotp
      command:
        - "--with-bootstrap"
      variables:
        LINOTP_DB_WAITTIME: 10s
        LINOTP_ADMIN_PASSWORD: admin
        LINOTP_LOG_LEVEL: INFO
        LINOTP_SESSION_COOKIE_SECURE: "false"
        # reenable selfservice for some e2e tests
        LINOTP_DISABLE_CONTROLLERS: "gettoken"
        LINOTP_SITE_ROOT_REDIRECT: ""
  script:
    - cd linotp/tests/integration
    - >
      /usr/local/bin/dockerfy
      --template docker_cfg.ini.tmpl:/tmp/server_cfg.ini
      --wait tcp://$SELENIUM_HOST:$SELENIUM_PORT
      --timeout 60m
      --wait tcp://$LINOTP_HOST:$LINOTP_PORT
      --timeout 60m
    - make integrationtests TCFILE=/tmp/server_cfg.ini PYTESTARGS="$PYTESTARGS"
  after_script:
    - mkdir -p linotp/tests/integration/Screenshots
    - mv linotp/tests/integration/Screenshots .
  artifacts:
    name: browser-screenshots
    paths:
      - Screenshots/
    when: on_failure
    reports:
      junit: linotp/tests/integration/e2e-*.xml

e2e-test-mariadb:
  extends:
    - .e2e-test
    - .mariadb-database
  services:
    - !reference [".e2e-test", "services"]
    - name: ${DB}
      alias: db
      command:
        [
          "mysqld",
          "--character-set-server=utf8",
          "--collation-server=utf8_unicode_ci",
        ]

e2e-test-mysql-lower-case-table-names:
  extends:
    - .e2e-test
    - .mysql-lower-case-table-names-database
  services:
    - !reference [".e2e-test", "services"]
    - !reference [".mysql-lower-case-table-names-database", "services"]
  script:
    - !reference [".e2e-test", "script"]
    - !reference [".mysql-lower-case-table-names-database", "script"]

e2e-test-postgres:
  extends:
    - .e2e-test
    - .postgres-database
  services:
    - !reference [".e2e-test", "services"]
    - name: ${DB}
      alias: db

e2e-test-softhsm:
  extends:
    - e2e-test-mariadb
    - .nightly-test-set-rules
  variables:
    ALL_JOB_ARGS: "-m smoketest -v"
  allow_failure: true
  parallel:
    # too few tests -> dont split
    matrix:
      - CI_NODE_INDEX: [1]
        CI_NODE_TOTAL: [1]

# Auto-generate API docs using Sphinx.
apidocs:
  stage: apidocs
  image: $PYPI_IMAGE_TAG
  interruptible: true
  needs: ["build-pypi"]
  before_script:
    - uv sync --locked --group apidocs --no-dev && PATH=${CI_PROJECT_DIR}/.venv/bin:$PATH
    - apt-get install -y make --no-install-recommends
  script:
    - cd ${CI_PROJECT_DIR}/api-doc
    - make apidocs
    - make html
    - mkdir ${CI_PROJECT_DIR}/api-docs
    - cp -a build/html/. ${CI_PROJECT_DIR}/api-docs
  artifacts:
    name: "linotp-apidocs"
    paths:
      - api-docs
    expire_in: 2 weeks

# Upload container image

# upload-container-image:
#   stage: upload
#   extends: .upload-container-image
